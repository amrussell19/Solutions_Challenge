# Solutions Challenge
1) Import a csv (complete)
2) Clean the data (complete, hopefully correct)
3) Fire off GET calls for all URL's within a specific field. (incomplete)
4) Pull Status of each URL and print (incomplete)

I opted to use Python 3 for the project as I have dabbled lightly (extremely lightly) with it in the past.

# Required installations
Anaconda was used to both run and install packages for this project

Anaconda install: https://www.anaconda.com/products/individual

Installing Navigator
Navigator is automatically installed when you install Anaconda version 4.0.0 or higher.

If you have Miniconda or an older version of Anaconda installed, you can install Navigator from an Anaconda Prompt by running the command ```conda install anaconda-navigator```

# Create & Activate Environment

To create your environment, start the anaconda prompt and type ```conda create --name myenv```

Once done, you will be required to activate the environment. Enter ```conda activate myenv```
replace 'myenv' with whatever name you wish for your environment

# Packages

Open anaconda prompt and install the below packages with the follownig commands

Numpy: https://anaconda.org/anaconda/numpy

```conda install -c anaconda numpy```

Pandas: https://anaconda.org/anaconda/pandas

```conda install -c anaconda pandas```

Requests: https://anaconda.org/anaconda/requests

```conda install -c anaconda requests```

when asked to proceed, type in 'y'

# Jupyter

After insalling Conda and it's packages, I was using JupyterLab to write out the code.
It's a good format that makes it easy to use code blocks and editting your code.

![image](https://user-images.githubusercontent.com/95093171/143609555-fdd42365-a84e-416f-821a-260e60f918c2.png)

